#!/usr/bin/env python
# -*- mode:python; indent-tabs-mode:nil; -*-
# vim:set expandtab shiftwidth=4 filetype=python:

from __future__ import with_statement

#import pdb; pdb.set_trace()

import sys, os, optparse, re, subprocess, struct, ConfigParser

objdump = 'objdump'
file_magic = 'DAR '
file_version = 201003171

class Err(Exception):
    pass

def w2bs(w):
    '''convert a 32-bit word into four bytes in big-endian order'''
    assert w >= 0
    assert w <= (1 << 32)
    assert struct.calcsize('>I') == 4
    return struct.pack('>I', w)

def str2bs(s):
    '''convert a string into length (one byte) followed by characters data'''
    return struct.pack('>256p', s)

def f2bs(f):
    '''convert a double into eight bytes in big-endian order'''
    assert struct.calcsize('>d') == 8
    return struct.pack('>d', f)

def p_nat(s, min=0):
    try: ans = int(s)
    except ValueError:
        try: ans = int(s,16)
        except ValueError: raise Err('not a natural number: %s' % s)
    if ans < min: raise Err('value %s must be >= %d' % (s, d))
    return ans
def p_prop(s):
    try: ans = float(s)
    except ValueError: raise Err('not a real number: %s' % s)
    if ans <= 0: raise Err('propensity not > 0: %s' % s)
    return ans

def read_section_headers(file, objdump_cmd='objdump', verbose=False):
    '''process file and section headers'''
    entry = None
    format = None
    sections = {}
    try:
        proc = subprocess.Popen([objdump_cmd, '-fh', file],
                                stdout=subprocess.PIPE)
        format_pat = re.compile(r'^.*file\s+format\s+(\S+)\s*$')
        entry_pat = re.compile(r'^\s*start\s+address\s+0x([0-9A-Fa-f]+)\s*$')
        info_pat = re.compile(r'^\s*\d+\s+(\S+)\s+([0-9A-Fa-f]+)\s+[0-9A-Fa-f]+\s+([0-9A-Fa-f]+)\s+[0-9A-Fa-f]+\s+2\*\*\d+\s*$')
        while True:
            l = proc.stdout.next().strip()
            m = format_pat.match(l)
            if m:
                assert(format is None)
                format = m.group(1)
                continue
            m = entry_pat.match(l)
            if m:
                assert(entry is None)
                entry = int(m.group(1), 16)
            m = info_pat.match(l)
            if m:
                name = m.group(1)
                if name in sections:
                    raise Err('duplicate section #%s' % name)
                sections[name] = { 'name': name,
                                   'size': int(m.group(2), 16),
                                   'lma': int(m.group(3), 16) }
                try:
                    l = proc.stdout.next().strip()
                except StopIteration:
                    raise Err('bad section %s header objdump' % name)
                sections[name]['flags'] = l.split(', ')
    except StopIteration:
        pass
    except OSError, e:
        raise Err('Failed to run %s: %s' % (objdump, e))
    if verbose:
        print 'file %s format %s' % (file, format)
        print '  entry point 0x%08x' % entry
        for k,v in sections.iteritems():
            print ('  section %s size %d at 0x%08x flags %s' %
                   (k, v['size'], v['lma'], ' '.join(v['flags'])))
    return file, format, entry, sections.values()

def sort_sections(all_secs, verbose=False):
    allocatable = [s for s in all_secs if 'ALLOC' in s['flags']]
    if len(allocatable) < 1:
        raise Err('there are no sections to allocate')
    ordered = sorted(allocatable, lambda s, t: cmp(s['lma'], t['lma']))
    for s in ordered:
        if 'RELOC' in s['flags']:
            raise Err('relocatable sections not supported (section %s)' % s)
    for s1, s2 in zip(ordered, ordered[1:]):
        if s1['lma'] + s1['size'] > s2['lma']:
            raise Err('sections %s and %s overlap' % (s1['name'],s2['name']))
    return ordered

def write_mem_image(out, file, start, size, entry, ordered_sections,
                    objdump_cmd='objdump', verbose=False):
    def write_hexs(s):
        assert len(s) % 2 == 0
        count = len(s) / 2
        while s != '':
            out.write(chr(int(s[:2], 16)))
            s = s[2:]
        return count
    def write_zeros(out, count):
        if count > 0:
            z4k = chr(0) * 4096
            for i in range(0, count / 4096):
                out.write(z4k)
            out.write(chr(0) * (count % 4096))
        return count
    contents_pat = re.compile(r'^\s*([0-9A-Fa-f]+)\s+([0-9A-Fa-f]+)\s+([0-9A-Fa-f]+)\s+([0-9A-Fa-f]+)\s+([0-9A-Fa-f]+)\s+')
    sp = start + size - 4  # stack starts on top of memory
    if verbose:
        print ('writing image at 0x%08x size 0x%08x entry 0x%08x stack 0x%08x' %
               (start, size, entry, sp))
    out.write(w2bs(start)) # memory image start address
    out.write(w2bs(size))  # memory image size
    where = start
    for sec in ordered_sections:
        if verbose: print 'processing section:', sec['name']
        assert (sec['lma'] - where) >= 0
        where += write_zeros(out, sec['lma'] - where)
        if 'LOAD' in sec['flags']:
            proc = subprocess.Popen([objdump_cmd, '-j', sec['name'], '-s',
                                     file], stdout=subprocess.PIPE)
            for l in proc.stdout:
                m = contents_pat.match(l.strip())
                if m:
                    addr = int(m.group(1), 16)
                    assert addr >= where
                    where += write_zeros(out, addr - where)
                    where += write_hexs(''.join(m.groups()[1:5]))
    where += write_zeros(out, start + size - where)
    out.write(w2bs(entry)) # entry point (initial PC)
    out.write(w2bs(sp))    # initial stack pointer

def write_header(out, verbose=False):
    if verbose:
        print ('writing header: magic \"%s\" version %d' %
                (file_magic, file_version))
    out.write(file_magic)
    out.write(w2bs(file_version))

def write_pe(out, id, core, img, n2b_bw, b2n_bw, b2n_xbar_bw, qmem_size,
             n2b_queues, b2n_queues, bytes_per_flit, one_q_per_f, one_f_per_q, 
             core_cfgs, memory_cfgs,
             multi_path_routing, verbose=False):
    core_id = {
        'mips_mpi':0,
        'injector':1,
        'memtraceCore':2,
        'mcpu':3
    }
    multi_path_routing_id = {
        'probability':0,
        'adaptive_queue':1,
        'adaptive_packet':2
    }
    if verbose:
        print 'writing PE %d' % id
    # node
    out.write(w2bs(id))
    out.write(w2bs(bytes_per_flit))
    out.write(w2bs(1 if one_q_per_f else 0))
    out.write(w2bs(1 if one_f_per_q else 0))
    if multi_path_routing_id.has_key(multi_path_routing):
        out.write(w2bs(multi_path_routing_id[multi_path_routing]))
    else:
        raise Err('bad multi-path routing scheme : %s (must be one of %s)' % (multi_path_routing, str(multi_path_routing.keys())))
    out.write(w2bs(qmem_size))
    # bridge
    out.write(w2bs(n2b_bw))
    out.write(w2bs(b2n_bw))
    out.write(w2bs(b2n_xbar_bw if b2n_xbar_bw is not None else 0xffffffff))
    # node->bridge connection
    out.write(w2bs(len(b2n_queues)))
    for q in b2n_queues: out.write(w2bs(q))
    out.write(w2bs(len(n2b_queues)))
    for q in n2b_queues: out.write(w2bs(q))
    if core_id.has_key(core):
        out.write(w2bs(core_id[core]))
    else:
        raise Err('bad core name : %s (must be one of %s)' % (core, str(core_id.keys())))

    ## -------------------------------------------------------------------------
    # mips data
    ## -------------------------------------------------------------------------
    if core == 'mips_mpi':
        assert(img is not None)
        file, format, entry, all_sections = \
                read_section_headers(img, verbose=verbose)
        sections = sort_sections(all_sections, verbose=verbose)
        start = sections[0]['lma'] & 0xfffff000
        addr_past_end = sections[-1]['lma'] + sections[-1]['size']
        size = ((addr_past_end - start) & 0xfffff000) + 0x1000 + 0x4000
        write_mem_image(out, file, start, size, entry, sections, verbose=verbose)
    ## -------------------------------------------------------------------------
    ## -------------------------------------------------------------------------
    if core == 'mcpu':
        file, format, entry, all_sections = \
                read_section_headers(img, verbose=verbose)
        sections = sort_sections(all_sections, verbose=verbose)
        start = sections[0]['lma'] & 0xfffff000
        addr_past_end = sections[-1]['lma'] + sections[-1]['size']
        size = ((addr_past_end - start) & 0xfffff000) + 0x1000 + 0x4000
        write_mem_image(out, file, start, size, entry, sections, verbose=verbose)
    ## -------------------------------------------------------------------------
    ## -------------------------------------------------------------------------

    # core specific configurations 
    for cfg in core_cfgs:
        out.write(w2bs(cfg))

    # memory specific configurations
    for cfg in memory_cfgs:
        out.write(w2bs(cfg))

def write_cxn(out, src, src_port, dst, dst_port, bw, xbar_bw, queues,
              verbose=False):
    if verbose:
        print (('writing connection %d:%s -> %d:%s with bandwidth %d '
                'and %d queues') %
                (src, src_port, dst, dst_port, bw, len(queues)))
    assert len(src_port) == 1
    assert len(dst_port) == 1
    out.write(w2bs(src))
    out.write(str2bs(src_port))
    out.write(w2bs(dst))
    out.write(str2bs(dst_port))
    out.write(w2bs(bw))
    out.write(w2bs(xbar_bw if xbar_bw is not None else 0xffffffff))
    out.write(w2bs(len(queues)))
    for q in queues: out.write(w2bs(q))

def write_route(out, (route_type, route), verbose=False):
    if verbose:
        print ('writing %s route for flow %08x at node %02x...' %
               (route_type, route[0], route[1]))
    def write_qs(qs):
        if verbose and qs != []:
            print ('  queues: ' +
                   ' '.join(['%02x@%3.2f' % (q,p) for (q,p) in qs]))
        out.write(w2bs(len(qs)))
        for qid, prop in qs:
            out.write(w2bs(qid))
            out.write(f2bs(prop))
    def write_bridge_route((flow, cur_n, qs)):
        out.write(w2bs(flow))
        out.write(w2bs(cur_n))
        out.write(w2bs(0xffffffff)) # indicates bridge route
        write_qs(qs)
    def write_node_route((flow, cur_n, prev_n, next_nodes)):
        if flow > (1 << 32):
            raise Err('flow ID exceeds 32 bits: 0x%x' % flow)
        if cur_n > (1 << 32):
            raise Err('node ID exceeds 32 bits: 0x%x' % cur_n)
        if prev_n > (1 << 32):
            raise Err('node ID exceeds 32 bits: 0x%x' % prev_n)
        out.write(w2bs(flow))
        out.write(w2bs(cur_n))
        out.write(w2bs(prev_n))
        out.write(w2bs(len(next_nodes)))
        assert next_nodes != []
        for next_n, next_f, prop, qs in next_nodes:
            if verbose and qs != []:
                print ('  next hop: node %02x>%08x@%3.2f' %
                       (next_n, next_f, prop))
            if next_f > (1 << 32):
                raise Err('flow ID exceeds 32 bits: 0x%x' % next_f)
            if next_n > (1 << 32):
                raise Err('node ID exceeds 32 bits: 0x%x' % next_n)
            out.write(w2bs(next_n))
            out.write(w2bs(next_f))
            out.write(f2bs(prop))
            write_qs(qs)
    assert route_type == 'bridge' or route_type == 'node'
    if route_type == 'bridge':
        write_bridge_route(route)
    else: # route_type == 'node'
        write_node_route(route)

def write_complete_image(out, cfg, verbose=False):
    network_width, settings, pes, cxns, routes = new_system_config(cfg, verbose=verbose)
    write_header(out, verbose=verbose)
    if verbose:
        print ('writing %d PE%s...' % (len(pes), '' if len(pes) == 1 else 's'))
    out.write(w2bs(len(pes)))
    out.write(w2bs(network_width))
    for pe_cfg in pes:
        write_pe(out=out, verbose=verbose, **pe_cfg)
    if verbose:
        print ('writing %d connection%s...' %
                (len(cxns), '' if len(cxns) == 1 else 's'))
    out.write(w2bs(settings['arbitration']))
    if settings['arbitration'] != 0:
        out.write(w2bs(settings['arbitration minimum bandwidth']))
        out.write(w2bs(settings['arbitration period']))
        out.write(w2bs(settings['arbitration delay']))
    out.write(w2bs(len(cxns)))
    for cxn_cfg in cxns: write_cxn(out=out, verbose=verbose, **cxn_cfg)
    if verbose:
        print ('writing %d route%s...' %
                (len(routes), '' if len(routes) == 1 else 's'))
    out.write(w2bs(len(routes)))
    for route in routes:
        write_route(out, route, verbose=verbose)

def get_core_cfgs(cfg, core):

    ret = []

    # memtraceCore
    if core == 'memtraceCore':
        section = 'core::memtraceCore'
        # em mode
        option_id = {
            'never':0,
            'distance':1,
            'always':2}
        if cfg.has_option(section, 'execution migration mode'):
            option = cfg.get(section, 'execution migration mode')  
            if option_id.has_key(option):
                ret.append(option_id[option])
            else:
                raise Err('bad execution migration mode name : %s (must be one of %s)' % (option, str(option_id.keys())))
        else:
            ret.append(option_id['never'])
        # message queue size
        if cfg.has_option(section, 'message queue size'):
            ret.append(int(cfg.get(section, 'message queue size')))
        else:
            ret.append(4)
        # migration context size in bytes
        if cfg.has_option(section, 'migration context size in bytes'):
            ret.append(int(cfg.get(section, 'migration context size in bytes')))
        else:
            ret.append(128)
        # maximum active thread per core 
        if cfg.has_option(section, 'maximum active threads per core'):
            ret.append(int(cfg.get(section, 'maximum active threads per core')))
        else:
            ret.append(2)

    return ret

def get_memory_cfgs(cfg, core):
    memory_id = {'private-shared MSI/MESI':0, 
                 'private-shared LCC':1,
                 'shared-shared RA':2,
                 'private-private MOESI':3}
    ret = []
    if core in ['mips_mpi', 'injector']:
        # need no memory configurations
        return ret

    # architecture
    if cfg.has_option('memory', 'architecture'):
        memory_arch = cfg.get('memory', 'architecture')
        if memory_id.has_key(memory_arch) == False:
            raise Err('bad memory architecture name : %s (must be one of %s)' % (memory_arch, str(memory_id.keys())))
    else:
        memory_arch = 'private-shared MSI/MESI'
    ret.append(memory_id[memory_arch])

    # dram controller location
    option_id = {
        'top and bottom':0,
        'boundary':1
    }
    if cfg.has_option('memory', 'dram controller location'):
        option = cfg.get('memory', 'dram controller location')
        if (option_id.has_key(option)):
            ret.append(option_id[option])
        else:
            raise Err('bad dram controller location name : %s (must be one of %s)' % (option, str(option_id.keys())))
    else:
        ret.append(option_id['top and bottom'])

    # core address translation 
    option_id = {
        'stripe':0,
        'static':1,
        'first touch':2
    }
    if cfg.has_option('memory', 'core address translation'):
        option = cfg.get('memory', 'core address translation')
        if (option_id.has_key(option)):
            ret.append(option_id[option])
        else:
            raise Err('bad core address translation name : %s (must be one of %s)' % (option, str(option_id.keys())))
    else:
        ret.append(option_id['stripe'])

    # core address translation latency 
    if cfg.has_option('memory', 'core address translation latency'):
        ret.append(int(cfg.get('memory', 'core address translation latency')))
    else:
        ret.append(1)

    # core address translation allocation unit
    if cfg.has_option('memory', 'core address translation allocation unit in bytes'):
        ret.append(int(cfg.get('memory', 'core address translation allocation unit in bytes')))
    else:
        ret.append(4096)

    # core address translation synch delay
    if cfg.has_option('memory', 'core address translation synch delay'):
        ret.append(int(cfg.get('memory', 'core address translation synch delay')))
    else:
        ret.append(0)

    # core address translation synch delay
    if cfg.has_option('memory', 'core address translation number of ports'):
        ret.append(int(cfg.get('memory', 'core address translation number of ports')))
    else:
        ret.append(0)

    # dram controller latency
    if cfg.has_option('memory', 'dram controller latency'):
        ret.append(int(cfg.get('memory', 'dram controller latency')))
    else:
        ret.append(2)

    # one-way offchip latency 
    if cfg.has_option('memory', 'one-way offchip latency'):
        ret.append(int(cfg.get('memory', 'one-way offchip latency')))
    else:
        ret.append(150)

    # dram latency
    if cfg.has_option('memory', 'dram latency'):
        ret.append(int(cfg.get('memory', 'dram latency')))
    else:
        ret.append(50)

    # dram message header size in words
    if cfg.has_option('memory', 'dram message header size in words'):
        ret.append(int(cfg.get('memory', 'dram message header size in words')))
    else:
        ret.append(4)

    # maximum requests in flight per dram controller
    if cfg.has_option('memory', 'maximum requests in flight per dram controller'):
        ret.append(int(cfg.get('memory', 'maximum requests in flight per dram controller')))
    else:
        ret.append(256)

    # bandwidth in words per dram controller 
    if cfg.has_option('memory', 'bandwidth in words per dram controller'):
        ret.append(int(cfg.get('memory', 'bandwidth in words per dram controller')))
    else:
        ret.append(4)

    if cfg.has_option('memory', 'address size in bytes'):
        ret.append(int(cfg.get('memory', 'address size in bytes')))
    else:
        ret.append(4)

    if memory_arch in ['private-shared LCC']:
        section = 'memory::' + memory_arch
        timestamp_logic_id = {'fixed':0, 'ideal':1, 'zero-delay':2}
        if cfg.has_option(section, 'timestamp logic'):
            answer = cfg.get(section, 'timestamp logic')
            if answer not in timestamp_logic_id.keys():
                raise Err('timestamp logic %s not supported (must be one of %s)' % (answer, str(timestamp_logic_id.keys())))
            else:
                ret.append(timestamp_logic_id[answer])
        else:
            ret.append(timestamp_logic_id['fixed'])
        if cfg.has_option(section, 'evict unexpired line and store timestamp in DRAM'):
            answer = cfg.get(section, 'evict unexpired line and store timestamp in DRAM')
            if answer in ['YES', 'yes', 'Y', 'y', '1', 'Yes', 'true', 'True', 'TRUE']:
                ret.append(1)
            else:
                ret.append(0)
        else:
            ret.append(0)
        if cfg.has_option(section, 'use separate VCs for write requests'):
            answer = cfg.get(section, 'use separate VCs for write requests')
            if answer in ['YES', 'yes', 'Y', 'y', '1', 'Yes', 'true', 'True', 'TRUE']:
                ret.append(1)
            else:
                ret.append(0)
        else:
            ret.append(0)
        if cfg.has_option(section, 'default timestamp delta'):
            ret.append(int(cfg.get(section, 'default timestamp delta')))
        else:
            ret.append(100)
        if cfg.has_option(section, 'shared L2 work table size'):
            ret.append(int(cfg.get(section, 'shared L2 work table size')))
        else:
            ret.append(4)
        if cfg.has_option(section, 'reserved L2 work table size for reads'):
            ret.append(int(cfg.get(section, 'reserved L2 work table size for reads')))
        else:
            ret.append(2)
        for cache_name in ['L1', 'L2']:
            option_id = {
                'LRU':0,
                'random':1,
                'nearest expiration and LRU':2,
                'nearest expiration and random':3 }
            if cfg.has_option(section, 'replacement policy in ' + cache_name):
                option = cfg.get(section, 'replacement policy in ' + cache_name)
                if (option_id.has_key(option)):
                    ret.append(option_id[option])
                else:
                    raise Err('bad cache replacement policy name : %s (must be one of %s)' % (option, str(option_id.keys())))
            else:
                ret.append(option_id['LRU'])


    if memory_arch in ['private-shared MSI/MESI']:
        section = 'memory::' + memory_arch
        if cfg.has_option(section, 'use Exclusive state'):
            answer = cfg.get(section, 'use Exclusive state')
            if answer in ['YES', 'yes', 'Y', 'y', '1', 'Yes', 'true', 'True', 'TRUE']:
                ret.append(1)
            else:
                ret.append(0)
        else:
            ret.append(0)
        if cfg.has_option(section, 'L1 work table size'):
            ret.append(int(cfg.get(section, 'L1 work table size')))
        else:
            ret.append(4)
        if cfg.has_option(section, 'shared L2 work table size'):
            ret.append(int(cfg.get(section, 'shared L2 work table size')))
        else:
            ret.append(4)
        if cfg.has_option(section, 'reserved L2 work table size for cache replies'):
            ret.append(int(cfg.get(section, 'reserved L2 work table size for cache replies')))
        else:
            ret.append(1)
        if cfg.has_option(section, 'reserved L2 work table size for line eviction'):
            ret.append(int(cfg.get(section, 'reserved L2 work table size for line eviction')))
        else:
            ret.append(1)
        for cache_name in ['L1', 'L2']:
            option_id = {
                'LRU':0,
                'random':1}
            if cfg.has_option(section, 'replacement policy in ' + cache_name):
                option = cfg.get(section, 'replacement policy in ' + cache_name)
                if (option_id.has_key(option)):
                    ret.append(option_id[option])
                else:
                    raise Err('bad cache replacement policy name : %s (must be one of %s)' % (option, str(option_id.keys())))
            else:
                ret.append(option_id['LRU'])

    # cache configuration (L1L2)
    if memory_arch in ['private-shared MSI/MESI', 'private-shared LCC', \
                       'shared-shared RA', 'private-private MOESI']:
        section = 'memory::' + memory_arch
        if cfg.has_option(section, 'words per cache line'):
            ret.append(int(cfg.get(section, 'words per cache line')))
        else:
            ret.append(8)
        if cfg.has_option(section, 'memory access ports for local core'):
            ret.append(int(cfg.get(section, 'memory access ports for local core')))
        else:
            ret.append(2)
        for cache_name in ['L1', 'L2']:
            if cfg.has_option(section, 'total lines in ' + cache_name):
                ret.append(int(cfg.get(section, 'total lines in ' + cache_name)))
            else:
                if cache_name in ['L1']:
                    ret.append(256)
                else:
                    ret.append(4096)
            if cfg.has_option(section, 'associativity in ' + cache_name):
                ret.append(int(cfg.get(section, 'associativity in ' + cache_name)))
            else:
                if cache_name in ['L1']:
                    ret.append(2)
                else:
                    ret.append(4)
            if cfg.has_option(section, 'hit test latency in ' + cache_name):
                ret.append(int(cfg.get(section, 'hit test latency in ' + cache_name)))
            else:
                if cache_name in ['L1']:
                    ret.append(2)
                else:
                    ret.append(4)
            if cfg.has_option(section, 'read ports in ' + cache_name):
                ret.append(int(cfg.get(section, 'read ports in ' + cache_name)))
            else:
                ret.append(2)
            if cfg.has_option(section, 'write ports in ' + cache_name):
                ret.append(int(cfg.get(section, 'write ports in ' + cache_name)))
            else:
                ret.append(1)
    return ret

def new_system_config(cfg, verbose=False):
    def get_links(w, h, n):
        return (([('north', 'N', n - w, 'S')] if n / w != 0 else []) +
                ([('east', 'E', n + 1, 'W')] if n % w != w - 1 else []) +
                ([('south', 'S', n + w, 'N')] if n / w != h - 1 else []) +
                ([('west', 'W', n - 1, 'E')] if n % w != 0 else []))
    def get_core((cores,dflt), id):
        core = cores[id] if id in cores else dflt
        return core
    def get_code((progs,dflt), id):
        code = progs[id] if id in progs else dflt
        if code is not None and not os.path.exists(code):
            raise Err('missing code image file: %s' % code)
        return code
    def get_qs(s): return [p_nat(n) for n in cfg.get('queues',s).split()]
    def get_bw(s):
        try:
            bw_ss = cfg.get('bandwidth',s).split('/')
            if len(bw_ss) < 1 or len(bw_ss) > 2:
                raise Err('bad bandwidth description: %s' % s)
            bw = p_nat(bw_ss[0], 1)
            xbar_bw = p_nat(bw_ss[1], 1) if len(bw_ss) > 1 else None
        except ValueError:
            raise Err('bad bandwidth description: %s' % s)
        return bw, xbar_bw
    def p_flow_nq(s):
        '''node:queue format'''
        fs = []
        try:
            for f in s.split():
                n, q = [p_nat(v) for v in f.split(':')]
                fs.append((n,[q]))
        except ValueError:
            raise Err('bad node:queue flows description: %s' % s)
        return fs
    def p_flow_nqs(s):
        '''node:queue format'''
        fs = []
        try:
            for f in s.split():
                n_s, qs_s = f.split(':')
                n = p_nat(n_s)
                qs = [p_nat(q) for q in qs_s.split(',')]
                fs.append((n,qs))
        except ValueError:
            raise Err('bad node:queue flows description: %s' % s)
        return fs
    def p_flow_n(s):
        '''node only format'''
        fs = []
        try:
            for f in s.split():
                n = p_nat(f)
                fs.append((n,[]))
        except ValueError:
            raise Err('bad node-only flows description: %s' % s)
        fs.append(fs[-1]) # duplicate last hop for node->bridge
        return fs
    def check_qs(dests):
        for d1 in dests:
            qs1 = set(get_qs(d1))
            for d2 in dests:
                overlap = qs1 & set(get_qs(d2))
                if d1 != d2 and len(overlap) > 0:
                    raise Err('queues for %s and %s overlap: %s' %
                              (d1, d2, ' '.join(map(str,overlap))))
    def check_flow_nqs(id, hops, links):
        # hops[0] should come from cpu
        if len(hops) < 1: raise Err('flow %s: empty flow' % id)
        first_n, first_qs = hops[0]
        for first_q in first_qs:
            if first_q not in get_qs('cpu'):
                raise Err(('flow %s: initial queue %02x:%02x does not '
                           'exit the CPU') % (id, first_n, first_q))
        last_n, last_qs = hops[-1]
        for last_q in last_qs:
            if last_q not in get_qs('net'):
                raise Err(('flow %s: final queue %02x:%02x does not exit '
                           'the network') % (id, last_n, last_q))
        for (src_n, _), (dst_n, dst_qs) in zip(hops, hops[1:-1]):
            if [l for l in links
                if l['src'] == src_n and l['dst'] == dst_n] == []:
                raise Err('flow %s: node %02x cannot route to node %02x' %
                          (id, src_n, dst_n))
            for dst_q in dst_qs:
                if [l for l in links
                    if (l['src'] == src_n and l['dst'] == dst_n
                        and dst_q in l['queues'])] == []:
                    raise Err(('flow %s: queue %02x:%02x does not come from '
                               'node %02x') % (id, dst_n, dst_q, src_n))
    def p_route((address, next_entries)):
        flow, prev_n, cur_n = 0xdeadbeef, 0xdeadbeef, 0xdeadbeef
        try:
            flow_s, prev_cur_s = address.split('@')
            prev_s, cur_s = prev_cur_s.split('->')
            flow = p_nat(flow_s.strip())
            prev_n = None if prev_s.strip() == '' else p_nat(prev_s.strip())
            cur_n = p_nat(cur_s.strip())
        except ValueError:
            raise Err('bad flow/node->node route: %s' % address)
        if prev_n is None: # bridge route, queues only
            qs = [(p_nat(q), 1.0) for q in next_entries.split(',')]
            return ('bridge', (flow, cur_n, qs))
        else:
            try:
                nexts = next_entries.split()
                next_ns = []
                if nexts == []:
                    raise Err('route %s has no next node info' % address)
                for next in nexts:
                    np_s, qs_s = next.split(':')
                    nf_s, p_s = np_s.split('@')
                    nf_ss = nf_s.split('>')
                    n_s = nf_ss[0]
                    if len(nf_ss) < 1 or len(nf_ss) > 2:
                        raise Err('bad entry for route %s: %s' %
                                  (address, next))
                    n = p_nat(n_s)
                    f = p_nat(nf_ss[1]) if len(nf_ss) > 1 else flow
                    p = p_prop(p_s)
                    qs = [(p_nat(q), 1.0) for q in qs_s.split(',')]
                    next_ns.append((n, f, p, qs))
                return ('node', (flow, cur_n, prev_n, next_ns))
            except ValueError:
                raise Err('bad entries for route %s: %s' %
                          (address,next_entries))
    # bridge: 0xf00@2->2 = 2:5,6,7
    # node: 0xf00@2->3: 1@0.2:5,4 2@0.5:8,9
    def flows_to_routes(flows):
        routes = []
        for flow, hops in flows:
            assert hops != []
            (cur_n, br_qs) = hops[0]
            routes.append(('bridge', (flow, cur_n, [(q,1.0) for q in br_qs])))
            prev_n = cur_n
            for next_n, next_qs in hops[1:]:
                qs = [(q,1.0) for q in next_qs]
                next_ns = [(next_n, flow, 1.0, qs)]
                routes.append(('node', (flow, cur_n, prev_n, next_ns)))
                prev_n = cur_n
                cur_n = next_n
        return routes
    try:
        if cfg.has_option('bandwidth', 'arbitration'):
            raise Err('arbitration scheme must be specified '
                      'via \'[arbitration] scheme\'')
        try:
            arb = cfg.get('arbitration', 'scheme')
        except ConfigParser.Error:
            arb = 'off'
        arbs = { 'off': 0, 'proportional': 1 }
        if arb not in arbs:
            raise Error('bad arbitration type: %s' % arbitration)
        if arb != 'off':
            if cfg.has_option('arbitration', 'minimum bandwidth'):
                arb_min_bw = cfg.getint('arbitration', 'minimum bandwidth')
            else:
                arb_min_bw = 0
            if cfg.has_option('arbitration', 'period'):
                arb_period = cfg.getint('arbitration', 'period')
                if arb_period < 1:
                    raise Err('arbitration period must be at least 1')
            else:
                arb_period = 1
            if cfg.has_option('arbitration', 'delay'):
                arb_delay = cfg.getint('arbitration', 'delay')
            else:
                arb_delay = 0
        else:
            arb_min_bw = 0
            arb_period = 1
            arb_delay = 0
        if cfg.has_option('routing', 'one queue per flow'):
            one_q_per_f = cfg.getboolean('routing', 'one queue per flow')
        else:
            one_q_per_f = False
        if cfg.has_option('routing', 'one flow per queue'):
            one_f_per_q = cfg.getboolean('routing', 'one flow per queue')
        else:
            one_f_per_q = False
        if cfg.has_option('routing', 'multi-path routing'):
            multi_path_routing = cfg.get('routing', 'multi-path routing')
        else:
            multi_path_routing = 'probability'
        node_routing = cfg.get('routing', 'node')
        if node_routing not in ['table', 'weighted']:
            raise Error('bad node routing type: %s' % node_routing)
        queue_routing_types = ['table', 'round-robin', 'set']
        queue_routing = cfg.get('routing', 'queue')
        if queue_routing not in queue_routing_types:
            raise Error('bad queue routing type: %s' % queue_routing)
        if node_routing == 'weighted' and queue_routing != 'set':
            raise Error('weighted node routing requires set queue routing')
        settings = { 'arbitration': arbs[arb],
                     'arbitration minimum bandwidth': arb_min_bw,
                     'arbitration period': arb_period,
                     'arbitration delay': arb_delay }
        w = p_nat(cfg.get('geometry', 'width'))
        h = p_nat(cfg.get('geometry', 'height'))
        check_qs(cfg.options('queues'))
        cores = (dict([(p_nat(n), v) for n, v in cfg.items('core')
                       if n != 'default']),
                 cfg.get('core','default') if cfg.has_option('core','default')
                                           else None)
        if cfg.has_section('code') :
            progs = (dict([(p_nat(n), v) for n, v in cfg.items('code')
                           if n != 'default']),
                     cfg.get('code','default') if cfg.has_option('code','default')
                                               else None)
        else :
            progs = ({}, None)
        
        node_ids = range(0, w * h)
        cpu_qs = get_qs('cpu')
        if get_bw('net')[1] is not None:
            raise Err('from-net bandwidth cannot have crossbar input limit')

        bytes_per_flit = int(cfg.get('bandwidth', 'bytes per flit')) if cfg.has_option('bandwidth', 'bytes per flit') else 8


        nodes = []
        for id in node_ids:
            core_cfgs = get_core_cfgs(cfg, get_core(cores, id))
            memory_cfgs = get_memory_cfgs(cfg, get_core(cores, id))
            nodes.append({ 'id': id,
                         'one_q_per_f': one_q_per_f,
                         'one_f_per_q': one_f_per_q,
                         'multi_path_routing' : multi_path_routing,
                         'core': get_core(cores, id),
                         'img': get_code(progs, id),
                         'n2b_bw': get_bw('net')[0],
                         'b2n_bw': get_bw('cpu')[0],
                         'b2n_xbar_bw': get_bw('cpu')[1],
                         'qmem_size': p_nat(cfg.get('node', 'queue size')),
                         'n2b_queues': get_qs('net'),
                         'b2n_queues': get_qs('cpu'),
                         'bytes_per_flit': bytes_per_flit,
                         'core_cfgs': core_cfgs,
                         'memory_cfgs': memory_cfgs})

        links = [{ 'src': src,
                   'src_port': src_port,
                   'dst': dst,
                   'dst_port': dst_port,
                   'bw': get_bw(dir)[0],
                   'xbar_bw': get_bw(dir)[1],
                   'queues': get_qs(dir) }
                 for dst in node_ids
                 for dir, dst_port, src, src_port in get_links(w, h, dst)]
        if node_routing == 'weighted':
            routes = [p_route(nv) for nv in cfg.items('flows')]
        elif queue_routing == 'table':
            for n, v in cfg.items('flows'):
                check_flow_nqs(n, p_flow_nq(v), links)
            flows = [(p_nat(n), p_flow_nq(v)) for n, v in cfg.items('flows')]
            routes = flows_to_routes(flows)
        elif queue_routing == 'round-robin':
            for n, v in cfg.items('flows'):
                check_flow_nqs(n, p_flow_n(v), links)
            flows = [(p_nat(n), p_flow_n(v)) for n, v in cfg.items('flows')]
            routes = flows_to_routes(flows)
        elif queue_routing == 'set':
            for n, v in cfg.items('flows'):
                check_flow_nqs(n, p_flow_nqs(v), links)
            flows = [(p_nat(n), p_flow_nqs(v)) for n, v in cfg.items('flows')]
            routes = flows_to_routes(flows)
        else:
            raise Err('bad queue routing type: %s' % queue_routing)
    except ConfigParser.Error, e:
        raise Err('bad config: %s' % e)
    return w, settings, nodes, links, routes

def main():
    out_file = 'output.img'
    try:
        usage = '%prog CONFIG...'
        opts_p = optparse.OptionParser(usage=usage)
        opts_p.add_option('-o', '--output', dest='outfile',
                          help='write memory image to FILE', metavar='FILE')
        opts_p.add_option('-v', '--verbose', dest='verbose',
                           action='store_true', default=False,
                           help='chatter more')
        opts, args = opts_p.parse_args()
        if opts.outfile: out_file = opts.outfile
        cfg = ConfigParser.SafeConfigParser()
        try:
            cfg.read(args)
        except Exception, e:
            raise Err('bad config: %s' % e)
        with open(out_file, 'wb') as out:
            write_complete_image(out, cfg, verbose=opts.verbose)
    except Err, e:
        print >>sys.stderr, 'ERROR:', e
        try:
            os.remove(out_file)
        except:
            pass
        sys.exit(1)
    except Exception, e:
        try:
            os.remove(out_file)
        except:
            pass
        raise e

if __name__ == '__main__': main()
